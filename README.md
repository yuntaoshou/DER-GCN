# Requirements
 pytorch 1.9.0
 torch-geometric 2.0.3
 scikit-learn 1.0.1
 CUDA 10.2 
 
# Dataset
The original datasets can be found at IEMOCAP and MELD.

In this work, we focus on ERC under a multimodal setting. Following MMGCN, raw utterance-level features of textual, acoustic, and visual modality are extracted by TextCNN, OpenSmile, and DenseNet, respectively.
